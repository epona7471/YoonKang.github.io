{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled96.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OBVtggtQgVW",
        "outputId": "8202cccf-b476-4eb7-a8c4-2123700b13eb"
      },
      "source": [
        "#Download a dataset\n",
        "\n",
        "#!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-14 13:52:38--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 64.233.189.128, 2404:6800:4008:c07::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|64.233.189.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1489096277 (1.4G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   1.39G  46.4MB/s    in 38s     \n",
            "\n",
            "2021-07-14 13:53:17 (37.6 MB/s) - ‘speech_commands_v0.01.tar.gz’ saved [1489096277/1489096277]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go1SICLUS9fS",
        "outputId": "4388d1a7-19f3-4069-8ea5-de6f71d3fb35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWHB8VnMS0yh"
      },
      "source": [
        "import shutil\n",
        "\n",
        "#unzip dataset\n",
        "\n",
        "#shutil.unpack_archive(\"/content/speech_commands_v0.01.tar.gz\", \"/content/drive/MyDrive/speech\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P52DoDiU03o"
      },
      "source": [
        "import librosa\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/speech/'\n",
        "JSON_PATH = DATASET_PATH + 'data.json'\n",
        "SAMPLES_TO_CONSIDER = 22050 # 1 sec worth of sound, Librosa recommendation"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61jjlzOXViPR"
      },
      "source": [
        "def prepare_dataset(dataset_path, json_path, n_mfcc=13, hop_length=512, n_fft=2048):\n",
        "\n",
        "    # data dictionary\n",
        "    data = {\n",
        "        'mappings': [],\n",
        "        'labels': [],\n",
        "        'MFCCs': [],\n",
        "        'files': []\n",
        "    }\n",
        "\n",
        "    # loop through all the sub-dirs\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # we need to ensure that we're not at root level\n",
        "        if dirpath is not dataset_path:\n",
        "              \n",
        "              # update mappings\n",
        "              category = dirpath.split('/')[-1] # dataset/down -> [dataset, down]\n",
        "              data['mappings'].append(category)\n",
        "              print(f'processing {category}')\n",
        "\n",
        "              # loop through all the filenames and etract MFCCs\n",
        "              for f in filenames:\n",
        "\n",
        "                  # get file path\n",
        "                  file_path = os.path.join(dirpath, f)\n",
        "                  # load audio file\n",
        "                  signal, sr = librosa.load(file_path)\n",
        "                  # ensure the audio file is at least 1 sec (to get same shape)\n",
        "                  if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "\n",
        "                      # enfoce 1 sec. long signal\n",
        "                      signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "                      # extract the MFCCs\n",
        "                      MFCCs = librosa.feature.mfcc(signal, n_mfcc=n_mfcc, hop_length=hop_length,\n",
        "                                                   n_fft=n_fft)\n",
        "\n",
        "                      # store data\n",
        "                      data['labels'].append(i-1)\n",
        "                      data['MFCCs'].append(MFCCs.T.tolist()) # ndarray to list\n",
        "                      data['files'].append(file_path)\n",
        "                      #print(f\"{file_path}: {i-1}\")\n",
        "\n",
        "    #store in jsonfile\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkj4z9jWZjgE",
        "outputId": "b8ba94f2-37a2-4fd1-8d57-c1aa0be949d2"
      },
      "source": [
        "prepare_dataset(DATASET_PATH, JSON_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing eight\n",
            "processing sheila\n",
            "processing nine\n",
            "processing yes\n",
            "processing one\n",
            "processing no\n",
            "processing left\n",
            "processing tree\n",
            "processing bed\n",
            "processing bird\n",
            "processing go\n",
            "processing wow\n",
            "processing seven\n",
            "processing marvin\n",
            "processing dog\n",
            "processing three\n",
            "processing two\n",
            "processing house\n",
            "processing down\n",
            "processing six\n",
            "processing five\n",
            "processing off\n",
            "processing right\n",
            "processing cat\n",
            "processing zero\n",
            "processing four\n",
            "processing stop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xodnc0cS7-cs"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/speech/data.json\"\n",
        "SAVED_MODEL_PATH = \"/content/drive/MyDrive/speech/model.h5\"\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUM_KEYWORDS = 30\n",
        "\n",
        "def load_dataset(data_path):\n",
        "\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "    \n",
        "    # extract inputs and targets\n",
        "    X = np.array(data[\"MFCCs\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def get_data_splits(data_path, test_size=0.1, test_validation=0.1):\n",
        "\n",
        "    # load dataset\n",
        "    X, y = load_dataset(data_path)\n",
        "\n",
        "    # create train/validation/test splits\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train,\n",
        "                                                                    test_size=test_validation)\n",
        "    # convert inpits from 2d to 3d arrays\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
        "\n",
        "\n",
        "def build_model(input_shape, learning_rate, error=\"sparse_categorical_crossentropy\"):\n",
        "\n",
        "    #build network\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # conv layer 1\n",
        "    model.add(keras.layers.Conv2D(64, (3,3), activation=\"relu\",\n",
        "                                  input_shape=input_shape, # initial layer\n",
        "                                  kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.MaxPool2D((3, 3),strides=(2,2), padding=\"same\"))\n",
        "    \n",
        "    # conv layer 2\n",
        "    model.add(keras.layers.Conv2D(32, (3,3), activation=\"relu\",\n",
        "                                  kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.MaxPool2D((3, 3),strides=(2,2), padding=\"same\"))\n",
        "    \n",
        "    # conv layer 3\n",
        "    model.add(keras.layers.Conv2D(32, (2,2), activation=\"relu\",\n",
        "                                  kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.MaxPool2D((2, 2),strides=(2,2), padding=\"same\"))\n",
        "    \n",
        "    # flatten the output feed it into a dense layer\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "    \n",
        "    # softmax classifier\n",
        "    model.add(keras.layers.Dense(NUM_KEYWORDS, activation=\"softmax\")) # []\n",
        "\n",
        "    #compile the model\n",
        "    optimiser = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimiser, loss=error, metrics=[\"accuracy\"])\n",
        "    \n",
        "    #print model overview\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "\n",
        "    # load train/validation/test data splits\n",
        "    X_train, X_validation, X_test, y_train, y_validation, y_test = get_data_splits(DATASET_PATH)\n",
        "\n",
        "    # build the CNN model\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]) # (# segments(MFCCs), # coefficients 13, 1)\n",
        "    model = build_model(input_shape, LEARNING_RATE)\n",
        "\n",
        "    # train the model\n",
        "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "              validation_data=(X_validation, y_validation))\n",
        "    \n",
        "    # evaluate the model\n",
        "    test_error, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test error: {test_error}, test accuracy: {test_accuracy}\")\n",
        "\n",
        "    # save the model\n",
        "    model.save(SAVED_MODEL_PATH)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v5G4Tebb2wq",
        "outputId": "99d4e52d-eefa-4c59-d3a2-fcedcf4ae835"
      },
      "source": [
        "main()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 42, 11, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 42, 11, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 21, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 19, 4, 32)         18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 19, 4, 32)         128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 10, 2, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 9, 1, 32)          4128      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 9, 1, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 5, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                10304     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 30)                1950      \n",
            "=================================================================\n",
            "Total params: 35,998\n",
            "Trainable params: 35,742\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "1475/1475 [==============================] - 6s 3ms/step - loss: 3.2497 - accuracy: 0.1340 - val_loss: 2.5555 - val_accuracy: 0.3241\n",
            "Epoch 2/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 2.3893 - accuracy: 0.3307 - val_loss: 1.8688 - val_accuracy: 0.5161\n",
            "Epoch 3/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 1.8617 - accuracy: 0.4735 - val_loss: 1.3823 - val_accuracy: 0.6456\n",
            "Epoch 4/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 1.4998 - accuracy: 0.5759 - val_loss: 1.0901 - val_accuracy: 0.7236\n",
            "Epoch 5/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 1.2595 - accuracy: 0.6462 - val_loss: 0.9314 - val_accuracy: 0.7665\n",
            "Epoch 6/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 1.0975 - accuracy: 0.6920 - val_loss: 0.8187 - val_accuracy: 0.7944\n",
            "Epoch 7/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.9869 - accuracy: 0.7261 - val_loss: 0.7413 - val_accuracy: 0.8125\n",
            "Epoch 8/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.9052 - accuracy: 0.7528 - val_loss: 0.6781 - val_accuracy: 0.8337\n",
            "Epoch 9/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.8439 - accuracy: 0.7683 - val_loss: 0.6671 - val_accuracy: 0.8358\n",
            "Epoch 10/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.7877 - accuracy: 0.7855 - val_loss: 0.6356 - val_accuracy: 0.8396\n",
            "Epoch 11/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.7517 - accuracy: 0.7971 - val_loss: 0.6375 - val_accuracy: 0.8302\n",
            "Epoch 12/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.7121 - accuracy: 0.8080 - val_loss: 0.5586 - val_accuracy: 0.8613\n",
            "Epoch 13/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.6775 - accuracy: 0.8199 - val_loss: 0.5401 - val_accuracy: 0.8655\n",
            "Epoch 14/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.6485 - accuracy: 0.8277 - val_loss: 0.5045 - val_accuracy: 0.8747\n",
            "Epoch 15/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.6240 - accuracy: 0.8343 - val_loss: 0.5321 - val_accuracy: 0.8682\n",
            "Epoch 16/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.6078 - accuracy: 0.8383 - val_loss: 0.4997 - val_accuracy: 0.8795\n",
            "Epoch 17/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.5866 - accuracy: 0.8453 - val_loss: 0.4751 - val_accuracy: 0.8800\n",
            "Epoch 18/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.5717 - accuracy: 0.8497 - val_loss: 0.4642 - val_accuracy: 0.8884\n",
            "Epoch 19/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.5575 - accuracy: 0.8530 - val_loss: 0.4600 - val_accuracy: 0.8861\n",
            "Epoch 20/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.5409 - accuracy: 0.8588 - val_loss: 0.4547 - val_accuracy: 0.8892\n",
            "Epoch 21/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.5302 - accuracy: 0.8601 - val_loss: 0.4603 - val_accuracy: 0.8823\n",
            "Epoch 22/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.5198 - accuracy: 0.8662 - val_loss: 0.4484 - val_accuracy: 0.8940\n",
            "Epoch 23/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.5115 - accuracy: 0.8655 - val_loss: 0.4319 - val_accuracy: 0.8947\n",
            "Epoch 24/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4967 - accuracy: 0.8703 - val_loss: 0.4359 - val_accuracy: 0.8926\n",
            "Epoch 25/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4876 - accuracy: 0.8716 - val_loss: 0.4169 - val_accuracy: 0.9001\n",
            "Epoch 26/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4791 - accuracy: 0.8747 - val_loss: 0.4129 - val_accuracy: 0.8987\n",
            "Epoch 27/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4717 - accuracy: 0.8751 - val_loss: 0.4020 - val_accuracy: 0.9029\n",
            "Epoch 28/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4601 - accuracy: 0.8793 - val_loss: 0.3902 - val_accuracy: 0.9054\n",
            "Epoch 29/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4559 - accuracy: 0.8811 - val_loss: 0.3982 - val_accuracy: 0.9046\n",
            "Epoch 30/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4508 - accuracy: 0.8847 - val_loss: 0.4156 - val_accuracy: 0.8962\n",
            "Epoch 31/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4461 - accuracy: 0.8841 - val_loss: 0.4164 - val_accuracy: 0.9006\n",
            "Epoch 32/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4345 - accuracy: 0.8891 - val_loss: 0.4499 - val_accuracy: 0.8852\n",
            "Epoch 33/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4295 - accuracy: 0.8886 - val_loss: 0.3904 - val_accuracy: 0.9025\n",
            "Epoch 34/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4233 - accuracy: 0.8908 - val_loss: 0.3690 - val_accuracy: 0.9079\n",
            "Epoch 35/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4194 - accuracy: 0.8912 - val_loss: 0.3791 - val_accuracy: 0.9088\n",
            "Epoch 36/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4109 - accuracy: 0.8927 - val_loss: 0.3946 - val_accuracy: 0.9054\n",
            "Epoch 37/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.4106 - accuracy: 0.8935 - val_loss: 0.3818 - val_accuracy: 0.9006\n",
            "Epoch 38/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.3945 - accuracy: 0.8990 - val_loss: 0.3894 - val_accuracy: 0.9020\n",
            "Epoch 39/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.3953 - accuracy: 0.8992 - val_loss: 0.3754 - val_accuracy: 0.9065\n",
            "Epoch 40/40\n",
            "1475/1475 [==============================] - 5s 3ms/step - loss: 0.3924 - accuracy: 0.8985 - val_loss: 0.3893 - val_accuracy: 0.9046\n",
            "183/183 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.9027\n",
            "Test error: 0.3982703685760498, test accuracy: 0.9026776552200317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWBKzRsUc05_"
      },
      "source": [
        "#ellipsis\n",
        "\n",
        "#[...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT4jCxTI0ccg"
      },
      "source": [
        "with open('/content/drive/MyDrive/speech/data.json', \"r\") as fp:\n",
        "    data = json.load(fp)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIAl8j1R03OQ",
        "outputId": "7a9f86f1-3109-4cd3-fb97-3a62d6b815ab"
      },
      "source": [
        "data['mappings']"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['eight',\n",
              " 'sheila',\n",
              " 'nine',\n",
              " 'yes',\n",
              " 'one',\n",
              " 'no',\n",
              " 'left',\n",
              " 'tree',\n",
              " 'bed',\n",
              " 'bird',\n",
              " 'go',\n",
              " 'wow',\n",
              " 'seven',\n",
              " 'marvin',\n",
              " 'dog',\n",
              " 'three',\n",
              " 'two',\n",
              " 'house',\n",
              " 'down',\n",
              " 'six',\n",
              " 'five',\n",
              " 'off',\n",
              " 'right',\n",
              " 'cat',\n",
              " 'zero',\n",
              " 'four',\n",
              " 'stop',\n",
              " 'up',\n",
              " 'on',\n",
              " 'happy',\n",
              " '.ipynb_checkpoints']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}